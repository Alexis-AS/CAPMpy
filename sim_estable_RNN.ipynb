{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librer√≠as\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from scipy.stats import norm, cauchy, levy_stable\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ResiduosDataset(Dataset):\n",
    "    def __init__(self, index_path, split):\n",
    "        self.index = pd.read_csv(index_path)\n",
    "        if isinstance(split, list):\n",
    "            self.index = self.index[self.index['split'].isin(split)]\n",
    "        else:\n",
    "            self.index = self.index[self.index['split'] == split]\n",
    "        self.index = self.index.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.index.iloc[idx]\n",
    "        table = pq.read_table(meta.path_archivo,\n",
    "                              columns=[\"Return\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\"],\n",
    "                              filters=[(\"Rep\", \"=\", meta.rep)])\n",
    "        serie = table.column(\"Return\").to_numpy().astype(\"float64\")\n",
    "        alpha = meta.alpha\n",
    "        beta = meta.beta\n",
    "        nombre = f\"{alpha}_{beta}_rep{meta.rep}\"\n",
    "        return serie, torch.tensor([alpha, beta], dtype=torch.float64), nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "INDEX_PATH= r\"D:\\OneDrive\\OneDrive - Universidad T√©cnica Federico Santa Mar√≠a\\2025\\Paper CAPM\\Simulaciones4\\index_master.csv\"\n",
    "\n",
    "#split dataset\n",
    "ds_pretrain = ResiduosDataset(index_path=INDEX_PATH, split=\"pre_train\")\n",
    "ds_pretrain = ResiduosDataset(index_path=INDEX_PATH, split=\"pre_train\")\n",
    "ds_train_raw = ResiduosDataset(index_path=INDEX_PATH, split=\"train\")\n",
    "ds_train = ConcatDataset([ds_pretrain, ds_train_raw])\n",
    "ds_val      = ResiduosDataset(index_path=INDEX_PATH, split=\"val\")\n",
    "ds_test     = ResiduosDataset(index_path=INDEX_PATH, split=\"test\")\n",
    "\n",
    "#dloader\n",
    "loader_pretrain = DataLoader(ds_pretrain, batch_size=128, shuffle=True, num_workers=0)\n",
    "loader_train    = DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=0)\n",
    "loader_val      = DataLoader(ds_val, batch_size=128, shuffle=False, num_workers=0)\n",
    "loader_test     = DataLoader(ds_test, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_pdf_series_infinity(x, alpha, beta, max_coef, device=None):\n",
    "    \"\"\"\n",
    "    Serie infinita para estimar la PDF de una distribuci√≥n estable con Œ± > 0.5.\n",
    "    \"\"\"\n",
    "    eps = 1e-16\n",
    "    if device is None:\n",
    "        device = x.device if torch.is_tensor(x) else \"cpu\"\n",
    "\n",
    "    # Asegurar float64\n",
    "    x = torch.as_tensor(x, dtype=torch.float64, device=device)\n",
    "    alpha = torch.as_tensor(alpha, dtype=torch.float64, device=device)\n",
    "    beta = torch.as_tensor(beta, dtype=torch.float64, device=device)\n",
    "\n",
    "    pi = torch.tensor(torch.pi, dtype=torch.float64, device=device)\n",
    "    zeta = -beta * torch.tan(pi * alpha / 2)\n",
    "    x_minus_zeta = x - zeta\n",
    "\n",
    "    if torch.any(x_minus_zeta <= 0):\n",
    "        raise ValueError(\"x - zeta contiene valores no positivos, lo que genera potencias negativas indefinidas.\")\n",
    "\n",
    "    k = torch.arange(0, max_coef + 1, dtype=torch.float64, device=device)  # 0 a max_coef\n",
    "    gamma_part = torch.exp(torch.lgamma(alpha * (k + 1)) - torch.lgamma(k + 1))  # gamma / k!\n",
    "    sin_part = torch.sin((pi / 2 * alpha - torch.atan(zeta)) * (k + 1))\n",
    "    sqrt_1pz2 = torch.sqrt(1 + zeta ** 2)\n",
    "    geometric_part = sqrt_1pz2 ** (k + 1)\n",
    "\n",
    "    # x-dependent part (potencias negativas acumuladas)\n",
    "    x_power = (x_minus_zeta.unsqueeze(-1)) ** (-alpha * (k + 1))  # shape: [len(x), len(k)]\n",
    "    x_div = 1.0 / (x_minus_zeta.unsqueeze(-1))  # x - zeta en el denominador\n",
    "\n",
    "    # Signo alternado (-1)^k\n",
    "    signs = (-1.0) ** k\n",
    "\n",
    "    # Producto escalar de todos los t√©rminos\n",
    "    terms = signs * gamma_part * geometric_part * sin_part  # shape: [len(k)]\n",
    "    full_terms = terms * x_power * x_div  # broadcasting sobre x\n",
    "\n",
    "    val = full_terms.sum(dim=-1) * alpha / pi  # sum sobre coeficientes\n",
    "\n",
    "    # Validaci√≥n\n",
    "    if torch.isnan(val).any() or (~torch.isfinite(val)).any():\n",
    "        raise ValueError(f\"[stable_pdf_series_infinity] Valores inv√°lidos ‚Äî Œ±={alpha.item()}, Œ≤={beta.item()}\")\n",
    "\n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_pdf_fourier_integral(x, alpha, beta):\n",
    "    \"\"\"\n",
    "    Estima la densidad de una distribuci√≥n estable usando el m√©todo de integral de Fourier\n",
    "    seg√∫n Ament & O‚ÄôNeill.\n",
    "    \"\"\"\n",
    "    eps = 1e-16\n",
    "    device = x.device if torch.is_tensor(x) else \"cpu\"\n",
    "    dtype = torch.float64\n",
    "\n",
    "    x = torch.as_tensor(x, dtype=dtype, device=device)\n",
    "    alpha = torch.as_tensor(alpha, dtype=dtype, device=device)\n",
    "    beta = torch.as_tensor(beta, dtype=dtype, device=device)\n",
    "\n",
    "    if alpha >= 1.1:\n",
    "        gx = torch.tensor([\n",
    "            7.0370416932351169e-06, 8.9457728587460458e-05, 4.5195717164507891e-04, 1.4387800013186535e-03,\n",
    "            3.4238229401029920e-03, 6.6679664869140516e-03, 1.1244527018077863e-02, 1.7062429312798121e-02,\n",
    "            2.3941528921398801e-02, 3.1681730492178345e-02, 4.0101739779817722e-02, 4.9052345082266816e-02,\n",
    "            5.8416313367213923e-02, 6.8103426617886029e-02, 7.8044751687152913e-02, 8.8187621674808730e-02,\n",
    "            9.8491651958493867e-02, 1.0892570482430752e-01, 1.1946561554032360e-01, 1.3009249854990793e-01,\n",
    "            1.4079148624023027e-01, 1.5155078763117422e-01, 1.6236098315732694e-01, 1.7321449381516493e-01,\n",
    "            1.8410517939724058e-01, 1.9502803262698309e-01, 2.0597894484676815e-01, 2.1695452535829091e-01,\n",
    "            2.2795196121330644e-01, 2.3896890767984083e-01, 2.5000340211253524e-01, 2.6105379579367261e-01,\n",
    "            2.7211869966031971e-01, 2.8319694083099400e-01, 2.9428752758178356e-01, 3.0538962098220246e-01,\n",
    "            3.1650251181003752e-01, 3.2762560167565286e-01, 3.3875838752038662e-01, 3.4990044884671112e-01,\n",
    "            3.6105143718373622e-01, 3.7221106735260195e-01, 3.8337911022287513e-01, 3.9455538670580470e-01,\n",
    "            4.0573976283971641e-01, 4.1693214574735116e-01, 4.2813248020546890e-01, 4.3934074598515077e-01,\n",
    "            4.5055695570150323e-01, 4.6178115355311344e-01, 4.7301341376196310e-01, 4.8425383952216777e-01,\n",
    "            4.9550256288736721e-01, 5.0675974549192959e-01, 5.1802557928302240e-01, 5.2930028492144732e-01,\n",
    "            5.4058411161129039e-01, 5.5187734378208209e-01, 5.6318030393397900e-01, 5.7449335812231850e-01,\n",
    "            5.8581688888130956e-01, 5.9715132998513110e-01, 6.0849716286556388e-01, 6.1985498063016387e-01,\n",
    "            6.3122540832012675e-01, 6.4260904482606040e-01, 6.5400647463066774e-01, 6.6541875634974845e-01,\n",
    "            6.7684685622122265e-01, 6.8829256028106156e-01, 6.9975558376055846e-01, 7.1123699066990020e-01,\n",
    "            7.2273896702242169e-01, 7.3426487948155317e-01, 7.4582269874591844e-01, 7.5740470496696566e-01,\n",
    "            7.6901033051191892e-01, 7.8063124635092274e-01, 7.9230651366491101e-01, 8.0410492102734399e-01,\n",
    "            8.1612625247941939e-01, 8.2818135034865736e-01, 8.4120303825748510e-01, 8.5677958040655922e-01,\n",
    "            8.7803721055848216e-01, 9.1078416473987345e-01\n",
    "        ], dtype=dtype, device=device)\n",
    "\n",
    "        gw = torch.tensor([\n",
    "            2.4123585761838668e-05, 1.7469393088180406e-04, 6.0975563988952377e-04, 1.4288650277602072e-03,\n",
    "            2.5860145358909906e-03, 3.9139638862970855e-03, 5.2225620441390059e-03, 6.3820155329709829e-03,\n",
    "            7.3422109186047540e-03, 8.1077876105023049e-03, 8.7073841240531413e-03, 9.1743792256825593e-03,\n",
    "            9.5386194524040412e-03, 9.8242023344950434e-03, 1.0049736076644946e-02, 1.0229323237713391e-02,\n",
    "            1.0373585169887569e-02, 1.0490520985968452e-02, 1.0586173608364573e-02, 1.0665129967020341e-02,\n",
    "            1.0730891859179584e-02, 1.0786149736593508e-02, 1.0832984766811224e-02, 1.0873018221674781e-02,\n",
    "            1.0907522259639847e-02, 1.0937502403629278e-02, 1.0963759233467768e-02, 1.0986934773375319e-02,\n",
    "            1.1007547570747180e-02, 1.1026019381147249e-02, 1.1042695595265807e-02, 1.1057860975532409e-02,\n",
    "            1.1071751857045479e-02, 1.1084565666505860e-02, 1.1096468395525276e-02, 1.1107600514184439e-02,\n",
    "            1.1118081666841355e-02, 1.1128014432939991e-02, 1.1137487348001939e-02, 1.1146577371101231e-02,\n",
    "            1.1155351893346113e-02, 1.1163870355731593e-02, 1.1172185618068415e-02, 1.1180345086850615e-02,\n",
    "            1.1188391761261667e-02, 1.1196364889593627e-02, 1.1204300700566747e-02, 1.1212232963606782e-02,\n",
    "            1.1220193879270582e-02, 1.1228214214753063e-02, 1.1236323377118574e-02, 1.1244550178188855e-02,\n",
    "            1.1252923441962841e-02, 1.1261473748637778e-02, 1.1270230850846127e-02, 1.1279221450164715e-02,\n",
    "            1.1288479658221117e-02, 1.1298037896021292e-02, 1.1307944646122644e-02, 1.1318225812893915e-02,\n",
    "            1.1328910209404287e-02, 1.1340046911577153e-02, 1.1351721380555410e-02, 1.1364027498287044e-02,\n",
    "            1.1376911984350185e-02, 1.1390449917960382e-02, 1.1404631513115529e-02, 1.1419998637800782e-02,\n",
    "            1.1436706611044661e-02, 1.1454320558660740e-02, 1.1472107181507585e-02, 1.1491546656562140e-02,\n",
    "            1.1511214906719663e-02, 1.1544621281952909e-02, 1.1568033041001595e-02, 1.1596005189903223e-02,\n",
    "            1.1611886374448196e-02, 1.1642999393803366e-02, 1.1703605655774101e-02, 1.1944617349004275e-02,\n",
    "            1.1998375088894278e-02, 1.2329022152040849e-02, 1.3931620772305212e-02, 1.7679054162172823e-02,\n",
    "            2.5992451059429083e-02, 3.9945131495550699e-02\n",
    "        ], dtype=dtype, device=device)\n",
    "\n",
    "    elif 0.5 <= alpha <= 0.9:\n",
    "        gx = torch.tensor([\n",
    "            3.7609390003375964e-08, 1.3685854979526549e-06, 1.4889428111233842e-05, 8.4909234018965159e-05,\n",
    "            3.1873821783035098e-04, 8.9204133360438380e-04, 2.0127465688419980e-03, 3.8618683453436136e-03,\n",
    "            6.5470889986536940e-03, 1.0090726664739097e-02, 1.4447552604036681e-02, 1.9533895674843968e-02,\n",
    "            2.5252790259180181e-02, 3.1509724331768026e-02, 3.8220152765976879e-02, 4.5311835199784489e-02,\n",
    "            5.2724547956529318e-02, 6.0408722152233675e-02, 6.8323799499387480e-02, 7.6436655143339735e-02,\n",
    "            8.4720214965027643e-02, 9.3152294763300211e-02, 1.0171464825117857e-01, 1.1039219699792262e-01,\n",
    "            1.1917241285088062e-01, 1.2804482522689517e-01, 1.3700062911969721e-01, 1.4603237349945128e-01,\n",
    "            1.5513371343540050e-01, 1.6429921251385121e-01, 1.7352418487154128e-01, 1.8280456842410028e-01,\n",
    "            1.9213682268853544e-01, 2.0151784603996090e-01, 2.1094490837374680e-01, 2.2041559602735405e-01,\n",
    "            2.2992776650187988e-01, 2.3947951105149096e-01, 2.4906912362070266e-01, 2.5869507493505961e-01,\n",
    "            2.6835599079492339e-01, 2.7805063380973916e-01, 2.8777788796725268e-01, 2.9753674557007820e-01,\n",
    "            3.0732629613371543e-01, 3.1714571693036520e-01, 3.2699426489914540e-01, 3.3687126977933890e-01,\n",
    "            3.4677612827216525e-01, 3.5670829904465617e-01, 3.6666729838885320e-01, 3.7665269672921287e-01,\n",
    "            3.8666411580352911e-01, 3.9670122617260967e-01, 4.0676374501492912e-01, 4.1685143449747197e-01,\n",
    "            4.2696410186536610e-01, 4.3710159821272931e-01, 4.4726381749484123e-01, 4.5745069603649885e-01,\n",
    "            4.6766221598520491e-01, 4.7789840652298787e-01, 4.8815934536220495e-01, 4.9844515052405652e-01,\n",
    "            5.0875598897275465e-01, 5.1909210453586785e-01, 5.2945380107118389e-01, 5.3984142933037105e-01,\n",
    "            5.5025535726907182e-01, 5.6069612221610865e-01, 5.7116437727195657e-01, 5.8166086578398579e-01,\n",
    "            5.9218626968330357e-01, 6.0274130153474181e-01, 6.1332726467412169e-01, 6.2394583575131990e-01,\n",
    "            6.3459902800886914e-01, 6.4528672842975432e-01, 6.5601051151983347e-01, 6.6677339218565990e-01,\n",
    "            6.7758442124720375e-01, 6.8844699690792643e-01, 6.9935285580563211e-01, 7.1030369804167903e-01,\n",
    "            7.2128236992493600e-01, 7.3240671216090558e-01, 7.4367772949733946e-01, 7.5519374839089404e-01,\n",
    "            7.6736343736510493e-01, 7.7970740763740065e-01, 7.9219118119668186e-01, 8.0570157617752125e-01,\n",
    "            8.2101055899513764e-01, 8.4330359349538586e-01\n",
    "        ], dtype=dtype, device=device)\n",
    "\n",
    "        gw = torch.tensor([\n",
    "            1.7500611765012179e-07, 3.8882557435783513e-06, 2.9954641912492096e-05, 1.2782804549555320e-04,\n",
    "            3.6976304598021047e-04, 8.1258486789405663e-04, 1.4598247640076655e-03, 2.2565489131548054e-03,\n",
    "            3.1172626255617855e-03, 3.9619509977401879e-03, 4.7373256373690322e-03, 5.4189419764267398e-03,\n",
    "            6.0029781163538484e-03, 6.4967663749125951e-03, 6.9120587945015596e-03, 7.2612932414371596e-03,\n",
    "            7.5558989407095746e-03, 7.8057162802363175e-03, 8.0189406936974315e-03, 8.2022775474879586e-03,\n",
    "            8.3611605279137139e-03, 8.4999707834225811e-03, 8.6222333472394299e-03, 8.7307842750017125e-03,\n",
    "            8.8279088186299960e-03, 8.9154535861816365e-03, 8.9949164606365779e-03, 9.0675180782155505e-03,\n",
    "            9.1342583376412181e-03, 9.1959609393384989e-03, 9.2533084527800825e-03, 9.3068699414011486e-03,\n",
    "            9.3571227648605662e-03, 9.4044698327488199e-03, 9.4492533078482065e-03, 9.4917655360856907e-03,\n",
    "            9.5322578036120403e-03, 9.5709473825848993e-03, 9.6080232366267462e-03, 9.6436506619579036e-03,\n",
    "            9.6779750821076437e-03, 9.7111251615898172e-03, 9.7432153882503012e-03, 9.7743482267823173e-03,\n",
    "            9.8046159138632880e-03, 9.8341019486747616e-03, 9.8628823752800656e-03, 9.8910269212001307e-03,\n",
    "            9.9185999146112931e-03, 9.9456610759173381e-03, 9.9722660729993397e-03, 9.9984675891846859e-03,\n",
    "            1.0024315689563553e-02, 1.0049857967087024e-02, 1.0075140023966186e-02, 1.0100206959935651e-02,\n",
    "            1.0125102938360671e-02, 1.0149871950774473e-02, 1.0174556113780179e-02, 1.0199197618018014e-02,\n",
    "            1.0223846640284091e-02, 1.0248548038151891e-02, 1.0273348419043692e-02, 1.0298288470141991e-02,\n",
    "            1.0323432854489152e-02, 1.0348849701458745e-02, 1.0374601974019832e-02, 1.0400712381956034e-02,\n",
    "            1.0427243781987490e-02, 1.0454389862197593e-02, 1.0482244702565721e-02, 1.0510876149932735e-02,\n",
    "            1.0540013946875334e-02, 1.0570289997603391e-02, 1.0601804398556677e-02, 1.0635579476156305e-02,\n",
    "            1.0670744865279679e-02, 1.0705103070143742e-02, 1.0742678704510395e-02, 1.0784424144377271e-02,\n",
    "            1.0838880134468544e-02, 1.0885073551248455e-02, 1.0926729010027615e-02, 1.0963337430818136e-02,\n",
    "            1.1008609571599130e-02, 1.1284106092130687e-02, 1.1237297680636530e-02, 1.1867898115707079e-02,\n",
    "            1.2386002478015653e-02, 1.2225388580440253e-02, 1.2967800176569934e-02, 1.3961994785569806e-02,\n",
    "            1.6951270842679722e-02, 3.1804594306850377e-02\n",
    "        ], dtype=dtype, device=device)\n",
    "    else:\n",
    "        raise ValueError(\"alpha in (0.9, 1.1): m√©todo no definido.\")\n",
    "        \n",
    "  # Escalamiento de cuadratura\n",
    "    rank_scaling = (-torch.log(torch.tensor(eps, dtype=dtype, device=device))) ** (1.0 / alpha)\n",
    "    gx_scaled = rank_scaling * gx\n",
    "    gw_scaled = rank_scaling / torch.pi * gw\n",
    "\n",
    "    gx_alpha = gx_scaled ** alpha\n",
    "    exp_term = torch.exp(-gx_alpha)\n",
    "\n",
    "    z = -beta * torch.tan(torch.pi * alpha / 2)\n",
    "\n",
    "    # Expansi√≥n para c√°lculo: broadcasting sobre nodos y valores x\n",
    "    x_col = x.unsqueeze(-1)  # shape: [len(x), 1]\n",
    "    gx_row = gx_scaled.unsqueeze(0)  # shape: [1, len(gx)]\n",
    "    gx_alpha_row = gx_alpha.unsqueeze(0)\n",
    "    exp_row = exp_term.unsqueeze(0)\n",
    "    gw_row = gw_scaled.unsqueeze(0)\n",
    "\n",
    "    h = (x_col - z) * gx_row + z * gx_alpha_row\n",
    "    cos_h = torch.cos(h)\n",
    "\n",
    "    integrand = gw_row * cos_h * exp_row\n",
    "    result = integrand.sum(dim=1)  # sum over j\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_sym_pdf_fourier_integral(x, alpha):\n",
    "    \"\"\"\n",
    "    Estima la densidad de una distribuci√≥n estable sim√©trica (Œ≤ = 0) \n",
    "    usando el m√©todo de integral de Fourier con cuadratura Gaussiana.\n",
    "    \"\"\"\n",
    "    eps = 1e-16\n",
    "    device = x.device if torch.is_tensor(x) else \"cpu\"\n",
    "    dtype = torch.float64\n",
    "\n",
    "    x = torch.as_tensor(x, dtype=dtype, device=device)\n",
    "    alpha = torch.as_tensor(alpha, dtype=dtype, device=device)\n",
    "\n",
    "    gx = torch.tensor([\n",
    "        2.7148704107693849e-08, 1.1539065574946093e-06, 1.4068944360213799e-05, 8.8528868370045850e-05,\n",
    "        3.6522895950416606e-04, 1.1242856520043885e-03, 2.7940849388937931e-03, 5.8998374370067466e-03,\n",
    "        1.0954815404797378e-02, 1.8308965706909420e-02, 2.7904977612154668e-02, 3.8402581477255261e-02,\n",
    "        4.7620451072357205e-02, 6.0322361829278297e-02, 7.7212543014189644e-02, 9.6567947626676073e-02,\n",
    "        1.1770638898039337e-01, 1.4023188371095557e-01, 1.6381653230311635e-01, 1.8807833684292100e-01,\n",
    "        2.1220569852597571e-01, 2.3337594286746213e-01, 2.5067518179499915e-01, 2.7308170043295299e-01,\n",
    "        2.9923165644921623e-01, 3.2670651619049274e-01, 3.5488605833898679e-01, 3.8356368161790211e-01,\n",
    "        4.1264154879954701e-01, 4.4206132991284341e-01, 4.7178318417560017e-01, 5.0177774958174326e-01,\n",
    "        5.3202251254241339e-01, 5.6249992102768298e-01, 5.9319640320449418e-01, 6.2410173262716340e-01,\n",
    "        6.5520873661416879e-01, 6.8651280590359287e-01, 7.1801277568472022e-01, 7.4971030516593817e-01,\n",
    "        7.8161424879996133e-01, 8.1374899659119626e-01, 8.4616111090172197e-01, 8.7910800331170069e-01,\n",
    "        9.1405149366238070e-01, 9.5623769770932743e-01\n",
    "    ], dtype=dtype, device=device)\n",
    "\n",
    "    gw = torch.tensor([\n",
    "        1.3158109639902134e-07, 3.4262543803194494e-06, 2.9760561009721337e-05, 1.4170149519462160e-04,\n",
    "        4.5818570532242872e-04, 1.1321935880671628e-03, 2.2968035970710459e-03, 4.0027607768915521e-03,\n",
    "        6.1688253884964774e-03, 8.5398963899097589e-03, 1.0476270652386517e-02, 9.8155372802538974e-03,\n",
    "        9.9827686069404245e-03, 1.5219506000563725e-02, 1.8284735354731164e-02, 2.0324582923350147e-02,\n",
    "        2.1888765891758585e-02, 2.3109125676823113e-02, 2.4000778165476255e-02, 2.4409563071531602e-02,\n",
    "        2.3429581499251423e-02, 1.8132920380634698e-02, 1.9021640675265461e-02, 2.4967741279101181e-02,\n",
    "        2.6986577522376015e-02, 2.7877980988375722e-02, 2.8450142752054142e-02, 2.8889685328033834e-02,\n",
    "        2.9256620565013172e-02, 2.9576419596863371e-02, 2.9862450428147645e-02, 3.0122958378570940e-02,\n",
    "        3.0363656749165541e-02, 3.0588909434433681e-02, 3.0802353645674175e-02, 3.1007120102372672e-02,\n",
    "        3.1206109628651280e-02, 3.1401812940439804e-02, 3.1598474495187191e-02, 3.1797517989457728e-02,\n",
    "        3.2015445283346267e-02, 3.2257598848695605e-02, 3.2604667010320047e-02, 3.3454059051937490e-02,\n",
    "        3.7403084267749798e-02, 4.8035994401521127e-02\n",
    "    ], dtype=dtype, device=device)\n",
    "\n",
    "  # Escalamiento de cuadratura\n",
    "    rank_scaling = (-torch.log(torch.tensor(eps, dtype=dtype, device=device))) ** (1.0 / alpha)\n",
    "    gx_scaled = rank_scaling * gx\n",
    "    gw_scaled = rank_scaling / torch.pi * gw\n",
    "\n",
    "    gx_alpha = gx_scaled ** alpha\n",
    "    exp_term = torch.exp(-gx_alpha)\n",
    "\n",
    "    # Broadcasting: [len(x), 1] vs [1, len(gx)]\n",
    "    x_col = x.unsqueeze(-1)\n",
    "    gx_row = gx_scaled.unsqueeze(0)\n",
    "    gw_row = gw_scaled.unsqueeze(0)\n",
    "    exp_row = exp_term.unsqueeze(0)\n",
    "\n",
    "    integrand = gw_row * torch.cos(x_col * gx_row) * exp_row\n",
    "    result = integrand.sum(dim=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versi√≥n PyTorch de ament_oneill_pdf, en float64 y replicando el flujo de R\n",
    "def ament_oneill_pdf(x, alpha, beta, device=None, verbose=True):\n",
    "    eps = 1e-16\n",
    "\n",
    "    x = torch.as_tensor(x, dtype=torch.float64)\n",
    "    alpha = torch.as_tensor(alpha, dtype=torch.float64)\n",
    "    beta = torch.as_tensor(beta, dtype=torch.float64)\n",
    "\n",
    "    if device is None:\n",
    "        device = x.device\n",
    "\n",
    "    pi = torch.tensor(torch.pi, dtype=torch.float64, device=device)\n",
    "    x = x.to(device)\n",
    "    alpha = alpha.to(device)\n",
    "    beta = beta.to(device)\n",
    "\n",
    "    z = -beta * torch.tan(pi * alpha / 2)\n",
    "\n",
    "    if beta.item() == 0:\n",
    "        n = 42\n",
    "        n_tensor = torch.tensor(n, dtype=torch.float64, device=device)\n",
    "\n",
    "        min_inf_x = ((alpha / (pi * eps)) * torch.exp(torch.lgamma(alpha * n_tensor) - torch.lgamma(n_tensor))) ** (1 / (alpha * n_tensor - 1))\n",
    "        x_abs = x.abs()\n",
    "\n",
    "        inf_cond = x_abs > min_inf_x\n",
    "        fourier_cond = ~inf_cond\n",
    "\n",
    "        pdf = torch.zeros_like(x, dtype=torch.float64)\n",
    "\n",
    "        if inf_cond.any():\n",
    "            pdf[inf_cond] = stable_pdf_series_infinity(x_abs[inf_cond], alpha, beta, n, device=device)\n",
    "\n",
    "        if fourier_cond.any():\n",
    "            pdf[fourier_cond] = stable_sym_pdf_fourier_integral(x_abs[fourier_cond], alpha)\n",
    "\n",
    "        return pdf\n",
    "\n",
    "    else:\n",
    "        alpha_val = alpha.item()\n",
    "        if 0.5 <= alpha_val <= 0.9:\n",
    "            n = 90\n",
    "        elif 1.1 <= alpha_val <= 2.0:\n",
    "            n = 80\n",
    "        else:\n",
    "            raise ValueError(\"Alpha fuera de rango permitido para Ament-O'Neill\")\n",
    "\n",
    "        pdf = torch.full_like(x, torch.nan, dtype=torch.float64)\n",
    "        xlz_cond = x < z\n",
    "\n",
    "        if xlz_cond.any():\n",
    "            pdf[xlz_cond] = ament_oneill_pdf(-x[xlz_cond], alpha, -beta, device=device, verbose=verbose)\n",
    "\n",
    "        if (~xlz_cond).any():\n",
    "            x_sub = x[~xlz_cond]\n",
    "            n_tensor = torch.tensor(n, dtype=torch.float64, device=device)\n",
    "            exp_term = torch.exp(torch.lgamma(alpha * n_tensor) - torch.lgamma(n_tensor))\n",
    "\n",
    "            base = (1 + z**2) ** (n_tensor / 2) * (alpha / (pi * eps)) * exp_term\n",
    "            denom = alpha * n_tensor - 1\n",
    "            min_inf_x = base ** (1 / denom) + z\n",
    "\n",
    "            inf_cond = x_sub > min_inf_x\n",
    "            fourier_cond = (x_sub > z) & (~inf_cond)\n",
    "\n",
    "            indices = torch.where(~xlz_cond)[0]\n",
    "\n",
    "            if inf_cond.any():\n",
    "                res_inf = stable_pdf_series_infinity(x_sub[inf_cond], alpha, beta, n, device=device)\n",
    "                pdf[indices[inf_cond]] = res_inf\n",
    "\n",
    "            if fourier_cond.any():\n",
    "                res_fourier = stable_pdf_fourier_integral(x_sub[fourier_cond], alpha, beta)\n",
    "                pdf[indices[fourier_cond]] = res_fourier\n",
    "\n",
    "        return pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stablepdf(x, alpha, beta, verbose=True):\n",
    "    # Validaci√≥n de par√°metros\n",
    "    alpha_val = alpha.item() if torch.is_tensor(alpha) else alpha\n",
    "    beta_val = beta.item() if torch.is_tensor(beta) else beta\n",
    "\n",
    "    if (not 0.1 <= alpha_val <= 2) or (abs(beta_val) > 1):\n",
    "        raise ValueError(\"Error: Par√°metros inv√°lidos\")\n",
    "\n",
    "    # Caso 1: Distribuci√≥n Normal (Œ± = 2, Œ≤ = 0)\n",
    "    elif alpha_val == 2 and beta_val == 0:\n",
    "        if verbose: print(\"Usando normal\")\n",
    "        vals = norm.pdf(x.detach().cpu().numpy(), loc=0, scale=1)\n",
    "        return torch.from_numpy(vals).to(x.device).to(dtype=x.dtype)\n",
    "\n",
    "    # Caso 2: Distribuci√≥n Cauchy (Œ± = 1)\n",
    "    elif alpha_val == 1:\n",
    "        if verbose: print(\"Usando Cauchy\")\n",
    "        vals = cauchy.pdf(x.detach().cpu().numpy(), loc=0, scale=1)\n",
    "        return torch.from_numpy(vals).to(x.device).to(dtype=x.dtype)\n",
    "\n",
    "    # Caso 3: Œ± ‚â§ 0.5 ‚Üí usar Nolan sin gradiente\n",
    "    elif alpha_val <= 0.5:\n",
    "        if verbose: print(f\"Usando Nolan (Œ± ‚â§ 0.5, sin gradiente) ‚Äî Œ±={alpha_val:.4f}, Œ≤={beta_val:.4f}\")\n",
    "        vals = levy_stable.pdf(x.detach().cpu().numpy(), alpha_val, beta_val)\n",
    "        val = torch.from_numpy(vals).to(x.device).to(dtype=x.dtype)\n",
    "        dummy = (alpha * 0 + beta * 0 + x[0])  # dummy conectado al grafo\n",
    "        return val + 0.0 * dummy\n",
    "\n",
    "    # Caso 4: Ament y O'Neill con Œ≤ = 0 (sim√©trica)\n",
    "    elif beta_val == 0:\n",
    "        if verbose: print(\"Ament-O‚ÄôNeill sim√©trica\")\n",
    "        return ament_oneill_pdf(x, alpha, beta)\n",
    "\n",
    "    # Caso 5: Œ± cercano a 1 con Œ≤ ‚â† 0 ‚Üí Nolan sin gradiente\n",
    "    elif 0.9 < alpha_val < 1.1 and beta_val != 0:\n",
    "        if verbose: print(\"Usando Nolan (zona cr√≠tica, sin gradiente)\")\n",
    "        vals = levy_stable.pdf(x.detach().cpu().numpy(), alpha_val, beta_val)\n",
    "        val = torch.from_numpy(vals).to(x.device).to(dtype=x.dtype)\n",
    "        dummy = (alpha * 0 + beta * 0 + x[0])  # dummy conectado\n",
    "        return val + 0.0 * dummy\n",
    "\n",
    "    # Caso 6: Ament y O'Neill general (asim√©trica)\n",
    "    else:\n",
    "        if verbose: print(\"Ament-O‚ÄôNeill asim√©trica\")\n",
    "        return ament_oneill_pdf(x, alpha, beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AICLossOnly(nn.Module):\n",
    "    def __init__(self, stablepdf, k=2, penalty=1e6, verbose=True):\n",
    "        super().__init__()\n",
    "        self.stablepdf = stablepdf\n",
    "        self.k = k\n",
    "        self.penalty = penalty\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, residuos_batch, alpha_beta_pred, alpha_beta_true, return_vector=False):\n",
    "        alpha = alpha_beta_pred[:, 0]\n",
    "        beta = alpha_beta_pred[:, 1]\n",
    "\n",
    "        loss_vals = alpha * 0.0  # mismo shape, dtype y grafo\n",
    "\n",
    "        try:\n",
    "            pdf_vals_list = []\n",
    "\n",
    "            for i in range(residuos_batch.size(0)):\n",
    "                x = residuos_batch[i]\n",
    "                a = alpha[i]\n",
    "                b = beta[i]\n",
    "                pdf_i = self.stablepdf(x, a, b, verbose=self.verbose)\n",
    "                pdf_vals_list.append(pdf_i)\n",
    "\n",
    "            pdf_vals = torch.stack(pdf_vals_list)  # (batch_size, len_serie)\n",
    "\n",
    "            # Penalizaci√≥n si hay problemas\n",
    "            invalid_mask = ~torch.isfinite(pdf_vals) | (pdf_vals <= 0)\n",
    "            if invalid_mask.any():\n",
    "                if self.verbose:\n",
    "                    print(f\"{invalid_mask.sum().item()} muestras AIC inv√°lidas penalizadas\")\n",
    "                loss_vals = torch.full_like(loss_vals, self.penalty)\n",
    "            else:\n",
    "                pdf_vals = torch.clamp(pdf_vals, min=1e-8)\n",
    "                logliks = torch.sum(torch.log(pdf_vals), dim=1)\n",
    "                aics = 2 * self.k - 2 * logliks\n",
    "                loss_vals = aics.to(loss_vals.dtype)\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f\"[AICLossOnly] AIC aplicado en {aics.size(0)} muestras\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"Error global al aplicar AIC: {e}\")\n",
    "            loss_vals = torch.full_like(loss_vals, self.penalty)\n",
    "\n",
    "        loss_mean = loss_vals.mean()\n",
    "        return (loss_mean, loss_vals) if return_vector else loss_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pretrain_loop(model, dataloader, optimizer, criterion,\n",
    "                      epochs=10, device=None, save_name=\"modelo_pretrain\",\n",
    "                      patience=5, min_delta=0.001, checkpoint_path=None):\n",
    "\n",
    "    import os, torch\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else device\n",
    "    model.to(device).double()\n",
    "\n",
    "    losses, mae_alphas, mae_betas = [], [], []\n",
    "\n",
    "    def calcular_mae(real, pred):\n",
    "        return torch.mean(torch.abs(real - pred)).item()\n",
    "\n",
    "    # early stopping\n",
    "    best_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    start_epoch = 0\n",
    "\n",
    "    # if checkpoint dale\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        best_loss = ckpt.get(\"best_loss\", float(\"inf\"))\n",
    "        epochs_no_improve = ckpt.get(\"epochs_no_improve\", 0)\n",
    "        start_epoch = ckpt.get(\"epoch\", -1) + 1\n",
    "        print(f\"Reanudando desde epoch {start_epoch} (mejor loss {best_loss:.6f})\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss, total_samples = 0.0, 0\n",
    "        all_alpha_real, all_beta_real = [], []\n",
    "        all_alpha_pred, all_beta_pred = [], []\n",
    "\n",
    "        skipped_nonfinite = 0\n",
    "        processed_batches = 0\n",
    "\n",
    "        for residuos_batch, targets, _ in tqdm(dataloader, desc=f\"[Pretrain] Epoch {epoch+1}/{epochs}\"):\n",
    "            residuos_batch = residuos_batch.to(device).double()\n",
    "\n",
    "            if isinstance(targets, list):\n",
    "                targets = torch.stack([torch.as_tensor(t) if not isinstance(t, torch.Tensor) else t for t in targets])\n",
    "            targets = targets.to(device).double()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            pred_params = model(residuos_batch)\n",
    "            loss, _ = criterion(residuos_batch, pred_params, targets, return_vector=True)\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                skipped_nonfinite += 1\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            #parche\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            bsz = residuos_batch.size(0)\n",
    "            total_loss += loss.item() * bsz\n",
    "            total_samples += bsz\n",
    "            processed_batches += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                all_alpha_real.append(targets[:, 0].detach().cpu())\n",
    "                all_beta_real.append(targets[:, 1].detach().cpu())\n",
    "                all_alpha_pred.append(pred_params[:, 0].detach().cpu())\n",
    "                all_beta_pred.append(pred_params[:, 1].detach().cpu())\n",
    "\n",
    "        if processed_batches == 0 or total_samples == 0:\n",
    "            # epoch fail\n",
    "            print(f\"Epoch {epoch+1}: todas las p√©rdidas fueron no finitas \"\n",
    "                  f\"(skipped={skipped_nonfinite}). Reducir lr / revisar datos.\")\n",
    "            epoch_loss = float(\"inf\")\n",
    "            mae_alpha = float(\"nan\")\n",
    "            mae_beta  = float(\"nan\")\n",
    "        else:\n",
    "            all_alpha_real = torch.cat(all_alpha_real)\n",
    "            all_beta_real  = torch.cat(all_beta_real)\n",
    "            all_alpha_pred = torch.cat(all_alpha_pred)\n",
    "            all_beta_pred  = torch.cat(all_beta_pred)\n",
    "\n",
    "            mae_alpha = calcular_mae(all_alpha_real, all_alpha_pred)\n",
    "            mae_beta  = calcular_mae(all_beta_real,  all_beta_pred)\n",
    "            epoch_loss = total_loss / max(total_samples, 1)\n",
    "\n",
    "        losses.append(epoch_loss)\n",
    "        mae_alphas.append(mae_alpha)\n",
    "        mae_betas.append(mae_beta)\n",
    "\n",
    "        # apply early stopping logic\n",
    "        if not torch.isfinite(torch.tensor(epoch_loss)):\n",
    "            delta = float(\"nan\")\n",
    "        elif best_loss == float(\"inf\"):\n",
    "            # epoch 1\n",
    "            best_loss = epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "            delta = float(\"inf\")\n",
    "            print(f\"üíæ Primer baseline guardado (loss: {best_loss:.6f})\")\n",
    "        else:\n",
    "            denom = max(abs(best_loss), 1e-12)\n",
    "            delta = (best_loss - epoch_loss) / denom\n",
    "            if delta > min_delta:\n",
    "                best_loss = epoch_loss\n",
    "                epochs_no_improve = 0\n",
    "                print(f\"üíæ Nuevo mejor modelo (loss: {best_loss:.6f}) ‚Äî mejora: {delta:.2%}\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"‚ö†Ô∏è Sin mejora sustancial ({delta:.2%}) ‚Äî {epochs_no_improve}/{patience}\")\n",
    "\n",
    "        # checkpoint save\n",
    "        if checkpoint_path:\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_loss\": best_loss,\n",
    "                \"epochs_no_improve\": epochs_no_improve\n",
    "            }, checkpoint_path)\n",
    "\n",
    "        # stop condition\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping activado en epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # parche\n",
    "    if len(losses) == 0:\n",
    "        return {\"loss_mean\": float(\"inf\"), \"mae_alpha\": float(\"nan\"),\n",
    "                \"mae_beta\": float(\"nan\"), \"best_loss\": float(\"inf\")}\n",
    "\n",
    "    return {\n",
    "        \"loss_mean\": float(sum(x for x in losses if x == x)) / max(len([x for x in losses if x == x]), 1),\n",
    "        \"mae_alpha\": float(sum(x for x in mae_alphas if x == x)) / max(len([x for x in mae_alphas if x == x]), 1),\n",
    "        \"mae_beta\":  float(sum(x for x in mae_betas  if x == x)) / max(len([x for x in mae_betas  if x == x]), 1),\n",
    "        \"best_loss\": float(best_loss)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#RNN\n",
    "def get_model(input_dim, hidden_size=64, dropout_rate=0.2,\n",
    "              num_layers=1, bidirectional=False):\n",
    "    class RNN(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_size, dropout_rate, num_layers, bidirectional):\n",
    "            super().__init__()\n",
    "            self.bidirectional = bidirectional\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=1,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_rate if num_layers > 1 else 0.0,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "            fc_input_size = hidden_size * (2 if bidirectional else 1)\n",
    "            self.fc = nn.Linear(fc_input_size, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # [batch, seq_len] ‚Üí [batch, seq_len, 1]\n",
    "            x = x.unsqueeze(-1)\n",
    "            out, _ = self.rnn(x)\n",
    "            last_output = out[:, -1, :]  # √∫ltima salida de la secuencia\n",
    "            out = self.fc(last_output)\n",
    "\n",
    "            # ALPHA en [1.1, 2], BETA en (-1, 1)\n",
    "            alpha_out = torch.clamp(torch.sigmoid(out[:, 0]), min=1e-6, max=1.0 - 1e-6)\n",
    "            beta_out = torch.clamp(torch.tanh(out[:, 1]), min=-0.999, max=0.999)\n",
    "\n",
    "            eps = 1e-4\n",
    "            alpha = (1.1 + eps) + alpha_out * ((2.0 - eps) - (1.1 + eps))\n",
    "            beta = beta_out\n",
    "            return torch.stack([alpha, beta], dim=1)\n",
    "\n",
    "    return RNN(input_dim, hidden_size, dropout_rate, num_layers, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain\n",
    "def run_pretrain_gridsearch(architecture, param_grid, input_dim,\n",
    "                            dataloader, criterion_class, optimizer_class,\n",
    "                            lr_key=\"lr\", epochs=15, device=\"cpu\", top_n=50,\n",
    "                            checkpoint_dir=\"checkpoints2\"):\n",
    "\n",
    "    import itertools\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    keys = list(param_grid.keys())\n",
    "    combos = list(itertools.product(*[param_grid[k] for k in keys]))\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for i, combo in enumerate(combos):\n",
    "        print(f\"\\n Pretrain combo {i+1}/{len(combos)} ‚Äî {architecture}\")\n",
    "        params = dict(zip(keys, combo))\n",
    "        model_params = {k: v for k, v in params.items()\n",
    "                        if k in [\"hidden_size\", \"dropout_rate\", \"num_layers\", \"bidirectional\"]}\n",
    "        lr = params.get(lr_key, 1e-4)\n",
    "        weight_decay = params.get(\"weight_decay\", 0.0)\n",
    "\n",
    "        combo_id = \"_\".join([f\"{k}{v}\" for k, v in params.items()])\n",
    "        save_name = f\"{architecture}_pretrain_{combo_id}\"\n",
    "\n",
    "        # checkpoint combinaci√≥n\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{save_name}.pth\")\n",
    "\n",
    "        model = get_model(input_dim, **model_params).to(device).double()\n",
    "        optimizer = optimizer_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        criterion = criterion_class(stablepdf, verbose=False)\n",
    "\n",
    "        resultado = run_pretrain_loop(\n",
    "            model=model,\n",
    "            dataloader=dataloader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            save_name=save_name,\n",
    "            patience=5,\n",
    "            min_delta=0.001,\n",
    "            checkpoint_path=checkpoint_path   # a√±adimos checkpoint persistente\n",
    "        )\n",
    "\n",
    "        resultado.update({\n",
    "            \"architecture\": architecture,\n",
    "            \"aic_mean\": resultado[\"loss_mean\"],\n",
    "            **params\n",
    "        })\n",
    "        resultados.append(resultado)\n",
    "\n",
    "    # Guardar resultado\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    df_resultados.to_csv(f\"gridsearch_pretrain_resultados_{architecture}.csv\", index=False)\n",
    "\n",
    "    # Extraer top-N por best_loss\n",
    "    df_top = df_resultados.sort_values(\"best_loss\").head(top_n)\n",
    "    df_top.to_csv(\"top50_pretrain.csv\", index=False)\n",
    "    print(f\"\\n Pretrain finalizado. Top {top_n} guardado en top50_pretrain.csv\")\n",
    "\n",
    "    return df_top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID\n",
    "param_grid_rnn = {\n",
    "    \"hidden_size\": [32, 64, 128, 256],\n",
    "    \"num_layers\": [1, 2, 3],\n",
    "    \"dropout_rate\": [0.0, 0.1, 0.2, 0.3],\n",
    "    \"bidirectional\": [False, True],\n",
    "    \"lr\": [1e-2, 1e-3, 1e-4, 5e-5],\n",
    "    \"weight_decay\": [0.0, 1e-5, 1e-4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNER\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def main_pretrain_runner():\n",
    "    input_dim = next(iter(loader_pretrain))[0].shape[1]\n",
    "    print(\"\\nIniciando GridSearch Pretrain para RNN\")\n",
    "    df_top_rnn = run_pretrain_gridsearch(\n",
    "        architecture=\"RNN\",\n",
    "        param_grid=param_grid_rnn,\n",
    "        input_dim=input_dim,\n",
    "        dataloader=loader_pretrain,\n",
    "        criterion_class=AICLossOnly,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        device=device,\n",
    "        epochs=10,\n",
    "        top_n=50\n",
    "    )\n",
    "\n",
    "    # === Guardar resumen global de los mejores modelos ===\n",
    "    df_top_rnn.assign(model=\"RNN\").to_csv(\"top50_pretrain_TODOS.csv\", index=False)\n",
    "    print(\"\\n Pretrain finalizado. Top 50 guardado en top50_pretrain_TODOS.csv\")\n",
    "    return df_top_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain_pretrain_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmain_pretrain_runner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain_pretrain_runner\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     input_dim = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader_pretrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].shape[\u001b[32m1\u001b[39m]\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIniciando GridSearch Pretrain para RNN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     df_top_rnn = run_pretrain_gridsearch(\n\u001b[32m      7\u001b[39m         architecture=\u001b[33m\"\u001b[39m\u001b[33mRNN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m         param_grid=param_grid_rnn,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         top_n=\u001b[32m50\u001b[39m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mResiduosDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     19\u001b[39m     meta = \u001b[38;5;28mself\u001b[39m.index.iloc[idx]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     table = \u001b[43mpq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath_archivo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReturn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAlpha\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGamma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDelta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m=\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     serie = table.column(\u001b[33m\"\u001b[39m\u001b[33mReturn\u001b[39m\u001b[33m\"\u001b[39m).to_numpy().astype(\u001b[33m\"\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     alpha = meta.alpha\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1774\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_table\u001b[39m(source, *, columns=\u001b[38;5;28;01mNone\u001b[39;00m, use_threads=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1765\u001b[39m                schema=\u001b[38;5;28;01mNone\u001b[39;00m, use_pandas_metadata=\u001b[38;5;28;01mFalse\u001b[39;00m, read_dictionary=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1766\u001b[39m                memory_map=\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size=\u001b[32m0\u001b[39m, partitioning=\u001b[33m\"\u001b[39m\u001b[33mhive\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1770\u001b[39m                thrift_container_size_limit=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1771\u001b[39m                page_checksum_verification=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1774\u001b[39m         dataset = \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m            \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m   1792\u001b[39m         \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[32m   1793\u001b[39m         \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[32m   1794\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1361\u001b[39m, in \u001b[36mParquetDataset.__init__\u001b[39m\u001b[34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m partitioning == \u001b[33m\"\u001b[39m\u001b[33mhive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1358\u001b[39m     partitioning = ds.HivePartitioning.discover(\n\u001b[32m   1359\u001b[39m         infer_dictionary=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[38;5;28mself\u001b[39m._dataset = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mparquet_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\pyarrow\\dataset.py:794\u001b[39m, in \u001b[36mdataset\u001b[39m\u001b[34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[39m\n\u001b[32m    783\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    784\u001b[39m     schema=schema,\n\u001b[32m    785\u001b[39m     filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m    790\u001b[39m     selector_ignore_prefixes=ignore_prefixes\n\u001b[32m    791\u001b[39m )\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Users\\Alexis Alfaro\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\pyarrow\\dataset.py:486\u001b[39m, in \u001b[36m_filesystem_dataset\u001b[39m\u001b[34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[39m\n\u001b[32m    478\u001b[39m options = FileSystemFactoryOptions(\n\u001b[32m    479\u001b[39m     partitioning=partitioning,\n\u001b[32m    480\u001b[39m     partition_base_dir=partition_base_dir,\n\u001b[32m    481\u001b[39m     exclude_invalid_files=exclude_invalid_files,\n\u001b[32m    482\u001b[39m     selector_ignore_prefixes=selector_ignore_prefixes\n\u001b[32m    483\u001b[39m )\n\u001b[32m    484\u001b[39m factory = FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main_pretrain_runner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
